"""AOTI Package"""

import os
import tempfile
from typing import Callable

import torch
import torch._inductor.package
import torch.utils._pytree as pytree
from torch._inductor.package.package import PT2ArchiveReader, compile_so
from torch._inductor.package.pt2_archive_constants import AOTINDUCTOR_DIR
from torch.export._tree_utils import reorder_kwargs

import torch_musa

# pylint: disable=no-else-raise


def load_package(path: str, device: str) -> Callable:  # type: ignore[type-arg]
    """
    Load an AOT Inductorâ€“compiled model package and return an optimized runner function.

    Parameters
    ----------
    path : str
        Path to the model package. Must be either:
        - A .pt2 archive file (AOT Inductor package).
        - A directory containing extracted AOT Inductor files.
    device : str
        Target device for execution. Supported values:
        - "cpu" for CPU execution.
        - "musa" or any string starting with "musa:" for MUSA devices.

    Returns
    -------
    Callable
        A function that wraps the AOTI runner. Its signature matches the original model:
        ``outputs = optimized(*args, **kwargs)``.

    """
    if path.endswith(".so"):
        raise RuntimeError(
            "Unable to load .so. It should be a .pt2 format or a directory."
        )

    elif path.endswith(".pt2"):
        so_path = os.path.splitext(path)[0]
        with PT2ArchiveReader(path) as archive_reader:
            file_names = archive_reader.get_file_names()

            with tempfile.TemporaryDirectory() as tmp_dir:
                archive_reader.extractall(tmp_dir)
                file_names = archive_reader.get_file_names()
                aoti_files = [
                    file for file in file_names if file.startswith(AOTINDUCTOR_DIR)
                ]

                so_path = compile_so(tmp_dir, aoti_files, so_path)

    else:
        assert os.path.isdir(path), "Must specify a directory or a .pt2 file"
        aoti_files = [
            os.path.join(root, file)
            for root, dirs, files in os.walk(path)
            for file in files
        ]
        so_path = compile_so(path, aoti_files, path)

    if device == "cpu":
        runner = torch._C._aoti.AOTIModelContainerRunnerCpu(so_path, 1)  # type: ignore[call-arg]
    elif device == "musa" or device.startswith("musa:"):
        runner = torch_musa._MUSAC._aoti.AOTIModelContainerRunnerMusa(
            so_path, 1, device
        )
    else:
        raise RuntimeError("Unsupported device " + device)

    def optimized(*args, **kwargs):  # type: ignore[no-untyped-def]
        call_spec = runner.get_call_spec()  # type: ignore[attr-defined]
        in_spec = pytree.treespec_loads(call_spec[0])
        out_spec = pytree.treespec_loads(call_spec[1])
        flat_inputs = pytree.tree_flatten((args, reorder_kwargs(kwargs, in_spec)))[0]
        flat_outputs = runner.run(flat_inputs)  # type: ignore[attr-defined]
        return pytree.tree_unflatten(flat_outputs, out_spec)

    return optimized


def _apply_package_patch():
    torch._inductor.package.package.load_package = load_package


_apply_package_patch()
