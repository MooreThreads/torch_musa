#ifndef ATEN_MUSA_MUSA_ATOMIC_H_
#define ATEN_MUSA_MUSA_ATOMIC_H_

#include <musa_runtime.h>
#include <stdint.h>

namespace at {
namespace musa {

typedef unsigned long long ull;
typedef __half float16_t;

#define ATOMIC_INTEGER_IMPL(NAME)                                              \
  template <typename T, size_t n>                                              \
  struct Atomic##NAME##IntegerImpl;                                            \
                                                                               \
  template <typename T>                                                        \
  struct Atomic##NAME##IntegerImpl<T, 1> {                                     \
    template <typename func_t>                                                 \
    inline __device__ void operator()(T* address, T val, const func_t& func) { \
      size_t offset = (size_t)address & 3;                                     \
      uint32_t* address_as_ui = (uint32_t*)((char*)address - offset);          \
      uint32_t old = *address_as_ui;                                           \
      uint32_t shift = offset * 8;                                             \
      uint32_t old_byte;                                                       \
      uint32_t newval;                                                         \
      uint32_t assumed;                                                        \
                                                                               \
      do {                                                                     \
        assumed = old;                                                         \
        old_byte = (old >> shift) & 0xff;                                      \
        newval = static_cast<uint8_t>(func(val, static_cast<T>(old_byte)));    \
        newval = (old & ~(0x000000ff << shift)) | (newval << shift);           \
        old = atomicCAS(address_as_ui, assumed, newval);                       \
      } while (assumed != old);                                                \
    }                                                                          \
  };                                                                           \
                                                                               \
  template <typename T>                                                        \
  struct Atomic##NAME##IntegerImpl<T, 2> {                                     \
    template <typename func_t>                                                 \
    inline __device__ void operator()(T* address, T val, const func_t& func) { \
      size_t offset = (size_t)address & 2;                                     \
      uint32_t* address_as_ui = (uint32_t*)((char*)address - offset);          \
      bool is_32_align = offset;                                               \
      uint32_t old = *address_as_ui;                                           \
      uint32_t old_bytes;                                                      \
      uint32_t newval;                                                         \
      uint32_t assumed;                                                        \
                                                                               \
      do {                                                                     \
        assumed = old;                                                         \
        old_bytes = is_32_align ? old >> 16 : old & 0xffff;                    \
        newval = static_cast<uint16_t>(func(val, static_cast<T>(old_bytes)));  \
        newval = is_32_align ? (old & 0xffff) | (newval << 16)                 \
                             : (old & 0xffff0000) | newval;                    \
        old = atomicCAS(address_as_ui, assumed, newval);                       \
      } while (assumed != old);                                                \
    }                                                                          \
  };                                                                           \
                                                                               \
  template <typename T>                                                        \
  struct Atomic##NAME##IntegerImpl<T, 4> {                                     \
    template <typename func_t>                                                 \
    inline __device__ void operator()(T* address, T val, const func_t& func) { \
      uint32_t* address_as_ui = (uint32_t*)(address);                          \
      uint32_t old = *address_as_ui;                                           \
      uint32_t newval;                                                         \
      uint32_t assumed;                                                        \
                                                                               \
      do {                                                                     \
        assumed = old;                                                         \
        newval = static_cast<uint32_t>(func(val, static_cast<T>(old)));        \
        old = atomicCAS(address_as_ui, assumed, newval);                       \
      } while (assumed != old);                                                \
    }                                                                          \
  };                                                                           \
                                                                               \
  template <typename T>                                                        \
  struct Atomic##NAME##IntegerImpl<T, 8> {                                     \
    template <typename func_t>                                                 \
    inline __device__ void operator()(T* address, T val, const func_t& func) { \
      ull* address_as_ui = (ull*)(address);                                    \
      ull old = *address_as_ui;                                                \
      ull newval;                                                              \
      ull assumed;                                                             \
                                                                               \
      do {                                                                     \
        assumed = old;                                                         \
        newval = static_cast<uint64_t>(func(val, static_cast<T>(old)));        \
        old = atomicCAS(address_as_ui, assumed, newval);                       \
      } while (assumed != old);                                                \
    }                                                                          \
  };

ATOMIC_INTEGER_IMPL(Add)

static inline __device__ float gpuAtomicAdd(float* address, float val) {
  return atomicAdd(address, val);
}

static inline __device__ float16_t
gpuAtomicAdd(float16_t* address, float16_t val) {
  return atomicAdd(address, val);
}

static inline __device__ void gpuAtomicAdd(at::Half* address, at::Half val) {
  atomicAdd(
      reinterpret_cast<float16_t*>(address),
      *reinterpret_cast<float16_t*>(&val));
}

static inline __device__ void gpuAtomicAdd(
    at::BFloat16* address,
    at::BFloat16 val) {
#if (defined(__MUSA_ARCH__) && __MUSA_ARCH__ >= 220)
  atomicAdd(
      reinterpret_cast<__mt_bfloat16*>(address),
      *reinterpret_cast<__mt_bfloat16*>(&val));
#else
  __float2bfloat16(0);
#endif
}

static inline __device__ double gpuAtomicAdd(double* address, double val) {
  return atomicAdd(address, val);
}

static inline __device__ __mt_bfloat16
gpuAtomicAdd(__mt_bfloat16* address, __mt_bfloat16 val) {
#if (defined(__MUSA_ARCH__) && __MUSA_ARCH__ >= 220)
  return atomicAdd(address, val);
#else
  return __float2bfloat16(0);
#endif
}

static inline __device__ void gpuAtomicAdd(uint8_t* address, uint8_t val) {
  AtomicAddIntegerImpl<uint8_t, sizeof(uint8_t)>()(
      address, val, [](uint8_t a, uint8_t b) { return a + b; });
}

static inline __device__ void gpuAtomicAdd(int8_t* address, int8_t val) {
  AtomicAddIntegerImpl<int8_t, sizeof(int8_t)>()(
      address, val, [](int8_t a, int8_t b) { return a + b; });
}

static inline __device__ void gpuAtomicAdd(int16_t* address, int16_t val) {
  AtomicAddIntegerImpl<int16_t, sizeof(int16_t)>()(
      address, val, [](int16_t a, int16_t b) { return a + b; });
}

static inline __device__ int32_t gpuAtomicAdd(int32_t* address, int32_t val) {
  return atomicAdd(address, val);
}

static inline __device__ void gpuAtomicAdd(int64_t* address, int64_t val) {
  AtomicAddIntegerImpl<int64_t, sizeof(int64_t)>()(
      address, val, [](int64_t a, int64_t b) { return a + b; });
}

static inline __device__ void gpuAtomicAdd(bool* address, bool val) {
  AtomicAddIntegerImpl<bool, sizeof(bool)>()(
      address, val, [](bool a, bool b) { return a || b; });
}

} // namespace musa
} // namespace at
#endif // ATEN_MUSA_MUSA_ATOMIC_H_
