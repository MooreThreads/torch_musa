"""_export init file"""

from typing import Callable
import torch
import torch.utils._pytree as pytree
from torch.export._tree_utils import reorder_kwargs
import torch_musa


def aot_load(so_path: str, device: str) -> Callable:
    """
    Loads a shared library generated by aot_compile and returns a callable

    Args:
        so_path: Path to the shared library
        device: Musa

    Returns:
        A callable
    """
    if device == "musa" or device.startswith("musa:"):
        runner = torch_musa._MUSAC._aoti.AOTIModelContainerRunnerMusa(
            so_path, 1, device
        )  # type: ignore[assignment, call-arg]
    elif device == "cpu":
        runner = torch._C._aoti.AOTIModelContainerRunnerCpu(so_path, 1)
    else:
        raise RuntimeError("Unsupported device " + device)

    def optimized(*args, **kwargs):
        call_spec = runner.get_call_spec()  # type: ignore[attr-defined]
        in_spec = pytree.treespec_loads(call_spec[0])
        out_spec = pytree.treespec_loads(call_spec[1])
        flat_inputs = pytree.tree_flatten((args, reorder_kwargs(kwargs, in_spec)))[0]
        flat_inputs = [x for x in flat_inputs if isinstance(x, torch.Tensor)]
        flat_outputs = runner.run(flat_inputs)  # type: ignore[attr-defined]
        return pytree.tree_unflatten(flat_outputs, out_spec)

    return optimized
