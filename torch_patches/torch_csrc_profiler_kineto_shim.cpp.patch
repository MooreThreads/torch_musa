diff --git a/torch/csrc/profiler/kineto_shim.cpp b/torch/csrc/profiler/kineto_shim.cpp
index 475effb..b7f2bec 100644
--- a/torch/csrc/profiler/kineto_shim.cpp
+++ b/torch/csrc/profiler/kineto_shim.cpp
@@ -22,18 +22,18 @@ const std::set<libkineto::ActivityType> kCpuTypes{
     libkineto::ActivityType::USER_ANNOTATION,
     libkineto::ActivityType::EXTERNAL_CORRELATION,
     libkineto::ActivityType::XPU_RUNTIME,
-    libkineto::ActivityType::CUDA_RUNTIME,
-    libkineto::ActivityType::CUDA_DRIVER,
+    libkineto::ActivityType::MUSA_RUNTIME,
+    libkineto::ActivityType::MUSA_DRIVER,
     libkineto::ActivityType::PYTHON_FUNCTION,
 };
 
-const std::set<libkineto::ActivityType> kCudaTypes = {
+const std::set<libkineto::ActivityType> kMusaTypes = {
     libkineto::ActivityType::GPU_MEMCPY,
     libkineto::ActivityType::GPU_MEMSET,
     libkineto::ActivityType::CONCURRENT_KERNEL,
-    // CUDA_RUNTIME appears in both kCpuTypes and kCudaTypes.
-    libkineto::ActivityType::CUDA_RUNTIME,
-    libkineto::ActivityType::CUDA_DRIVER,
+    // MUSA_RUNTIME appears in both kCpuTypes and kMusaTypes.
+    libkineto::ActivityType::MUSA_RUNTIME,
+    libkineto::ActivityType::MUSA_DRIVER,
 };
 const std::set<libkineto::ActivityType> kXpuTypes = {
     libkineto::ActivityType::GPU_MEMCPY,
@@ -46,6 +46,12 @@ const std::set<libkineto::ActivityType> kMtiaTypes = {
     libkineto::ActivityType::MTIA_CCP_EVENTS,
     libkineto::ActivityType::MTIA_RUNTIME,
 };
+const std::set<libkineto::ActivityType> mtTimerCPUTypes{
+    libkineto::ActivityType::USER_ANNOTATION,
+};
+const std::set<libkineto::ActivityType> mtTimerGPUTypes{
+    libkineto::ActivityType::CONCURRENT_KERNEL,
+};
 } // namespace
 #endif // USE_KINETO
 
@@ -165,7 +171,7 @@ class ExperimentalConfigWrapper {
   void prepareTraceWithExperimentalOptions(bool add_cpu_activity) {
 #ifdef USE_KINETO
     std::set<libkineto::ActivityType> k_activities{
-        libkineto::ActivityType::CUDA_PROFILER_RANGE};
+        libkineto::ActivityType::MUSA_PROFILER_RANGE};
 
     // Only add CPU activities if we are measuring per kernel ranges
     if (add_cpu_activity && config_.profiler_measure_per_kernel) {
@@ -175,10 +181,10 @@ class ExperimentalConfigWrapper {
     const size_t num_metrics = config_.profiler_metrics.size();
     std::stringstream configss;
 
-    LOG(INFO) << "CUPTI profiler metrics size = " << num_metrics;
+    LOG(INFO) << "MUPTI profiler metrics size = " << num_metrics;
 
     configss << "ACTIVITIES_WARMUP_PERIOD_SECS=0\n"
-             << "CUPTI_PROFILER_METRICS=";
+             << "MUPTI_PROFILER_METRICS=";
 
     for (size_t i = 0; i < num_metrics; i++) {
       configss << config_.profiler_metrics[i];
@@ -186,7 +192,33 @@ class ExperimentalConfigWrapper {
         configss << ",";
       }
     }
-    configss << "\nCUPTI_PROFILER_ENABLE_PER_KERNEL="
+    configss << "\nMUPTI_PROFILER_ENABLE_PER_KERNEL="
+             << (config_.profiler_measure_per_kernel ? "true" : "false")
+             << "\n";
+    LOG(INFO) << "Generated config = " << configss.str();
+
+    libkineto::api().activityProfiler().prepareTrace(
+        k_activities, configss.str());
+#endif // USE_KINETO
+  }
+
+  void prepareTraceWithExperimentalOptions(std::set<libkineto::ActivityType>& k_activities) {
+#ifdef USE_KINETO
+    const size_t num_metrics = config_.profiler_metrics.size();
+    std::stringstream configss;
+
+    LOG(INFO) << "MUPTI profiler metrics size = " << num_metrics;
+
+    configss << "ACTIVITIES_WARMUP_PERIOD_SECS=0\n"
+             << "MUPTI_PROFILER_METRICS=kineto__musa_core_flops\n";
+
+    for (size_t i = 0; i < num_metrics; i++) {
+      configss << config_.profiler_metrics[i];
+      if (num_metrics > 1 && i < (num_metrics - 1)) {
+        configss << ",";
+      }
+    }
+    configss << "\nMUPTI_PROFILER_ENABLE_PER_KERNEL="
              << (config_.profiler_measure_per_kernel ? "true" : "false")
              << "\n";
     LOG(INFO) << "Generated config = " << configss.str();
@@ -207,8 +239,10 @@ void prepareTrace(
     const ActivitySet& activities,
     const torch::profiler::impl::ExperimentalConfig& config) {
 #ifdef USE_KINETO
+  bool enable_mt_timer_cpu_events = (std::getenv("MT_TIMER_CPU_EVENTS") != nullptr);
+  bool enable_mt_timer_gpu_events = (std::getenv("MT_TIMER_GPU_EVENTS") != nullptr);
   if (!libkineto::api().isProfilerRegistered()) {
-    libkineto_init(/*cpuOnly=*/cpuOnly, /*logOnError=*/true);
+    libkineto_init(/*cpuOnly=*/enable_mt_timer_cpu_events && !enable_mt_timer_gpu_events, /*logOnError=*/true);
     libkineto::api().suppressLogMessages();
   }
 
@@ -220,8 +254,17 @@ void prepareTrace(
   bool has_cpu_activity =
       activities.count(torch::autograd::profiler::ActivityType::CPU);
 
-  if (has_cpu_activity) {
-    k_activities.insert(kCpuTypes.begin(), kCpuTypes.end());
+  if (!enable_mt_timer_cpu_events && !enable_mt_timer_gpu_events) {
+    if (has_cpu_activity) {
+        k_activities.insert(kCpuTypes.begin(), kCpuTypes.end());
+    }
+    k_activities.insert(kMusaTypes.begin(), kMusaTypes.end());
+  }
+  if (enable_mt_timer_cpu_events) {
+    k_activities.insert(mtTimerCPUTypes.begin(), mtTimerCPUTypes.end());
+  }
+  if (enable_mt_timer_gpu_events) {
+    k_activities.insert(mtTimerGPUTypes.begin(), mtTimerGPUTypes.end());
   }
   if (activities.count(torch::autograd::profiler::ActivityType::XPU)) {
     k_activities.insert(kXpuTypes.begin(), kXpuTypes.end());
@@ -229,19 +272,11 @@ void prepareTrace(
   if (activities.count(torch::autograd::profiler::ActivityType::MTIA)) {
     k_activities.insert(kMtiaTypes.begin(), kMtiaTypes.end());
   }
-  if (activities.count(torch::autograd::profiler::ActivityType::CUDA)) {
-    k_activities.insert(kCudaTypes.begin(), kCudaTypes.end());
-    if (config.enable_cuda_sync_events || get_cuda_sync_enabled()) {
-      LOG(INFO) << "Enabling CUDA Sync Events";
-      k_activities.insert(libkineto::ActivityType::CUDA_SYNC);
-    }
-  }
-
   ExperimentalConfigWrapper configWrap(config);
 
   // Experimental Configuration options are present
-  if (config && configWrap.assertValid()) {
-    configWrap.prepareTraceWithExperimentalOptions(has_cpu_activity);
+  if (config) {
+    configWrap.prepareTraceWithExperimentalOptions(k_activities);
     return;
   }
 
@@ -320,22 +355,31 @@ c10::DeviceType deviceTypeFromActivity(libkineto::ActivityType activity_type) {
     case libkineto::ActivityType::GPU_MEMCPY:
     case libkineto::ActivityType::GPU_MEMSET:
     case libkineto::ActivityType::CONCURRENT_KERNEL:
-    case libkineto::ActivityType::CUDA_SYNC:
+#ifdef USE_KINETO
+    case libkineto::ActivityType::MUSA_SYNC:
+#endif
     case libkineto::ActivityType::GPU_USER_ANNOTATION:
-    case libkineto::ActivityType::CUDA_PROFILER_RANGE:
     // TODO: T151322015
     case libkineto::ActivityType::MTIA_CCP_EVENTS:
-      return c10::DeviceType::CUDA;
+     return c10::DeviceType::CUDA;
+#ifdef USE_KINETO
+    case libkineto::ActivityType::MUSA_PROFILER_RANGE:
+      return c10::DeviceType::PrivateUse1;
+#endif
     case libkineto::ActivityType::CPU_OP:
     case libkineto::ActivityType::USER_ANNOTATION:
     case libkineto::ActivityType::EXTERNAL_CORRELATION:
-    case libkineto::ActivityType::CUDA_RUNTIME:
+#ifdef USE_KINETO
+    case libkineto::ActivityType::MUSA_RUNTIME:
+#endif
     case libkineto::ActivityType::CPU_INSTANT_EVENT:
     case libkineto::ActivityType::GLOW_RUNTIME:
     case libkineto::ActivityType::MTIA_RUNTIME:
     case libkineto::ActivityType::PYTHON_FUNCTION:
-    case libkineto::ActivityType::CUDA_DRIVER:
+#ifdef USE_KINETO
+    case libkineto::ActivityType::MUSA_DRIVER:
       return c10::DeviceType::CPU;
+#endif
     default: {
       TORCH_WARN(
           "Unknown activity type (",
@@ -346,6 +390,20 @@ c10::DeviceType deviceTypeFromActivity(libkineto::ActivityType activity_type) {
   }
 }
 
+bool isSyncProfilingRunning() {
+#ifdef USE_KINETO
+  return libkineto::api().activityProfiler().isSyncProfilingRunning();
+#else
+  return true; // if USE_KINETO NOT defined, just return true.
+#endif // USE_KINETO
+}
+
+void setSyncProfilingRunningFalse() {
+#ifdef USE_KINETO
+  libkineto::api().activityProfiler().setSyncProfilingRunning(false);
+#endif // USE_KINETO
+}
+
 void addMetadataJson(const std::string& key, const std::string& value) {
 #ifdef USE_KINETO
   if (libkineto::api().isProfilerInitialized()) {
