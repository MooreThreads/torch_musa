diff --git a/torch/csrc/inductor/aoti_runtime/device_utils.h b/torch/csrc/inductor/aoti_runtime/device_utils.h
index 7673199..7144d38 100644
--- a/torch/csrc/inductor/aoti_runtime/device_utils.h
+++ b/torch/csrc/inductor/aoti_runtime/device_utils.h
@@ -5,45 +5,25 @@
 // C ABI defined in torch/csrc/inductor/aoti_torch/c/shim.h. The same rule
 // applies to other files under torch/csrc/inductor/aoti_runtime/.
 
-#ifdef USE_CUDA
-
-// FIXME: Currently, CPU and CUDA backend are mutually exclusive.
+// FIXME: Currently, CPU and MUSA backend are mutually exclusive.
 // This is a temporary workaround. We need a better way to support
 // multi devices.
 
-#include <cuda.h>
-#include <cuda_runtime_api.h>
+#include <musa.h>
+#include <musa_runtime_api.h>
 
 #define AOTI_RUNTIME_DEVICE_CHECK(EXPR)                    \
   do {                                                     \
-    const cudaError_t code = EXPR;                         \
-    const char* msg = cudaGetErrorString(code);            \
-    if (code != cudaSuccess) {                             \
+    const musaError_t code = EXPR;                         \
+    const char* msg = musaGetErrorString(code);            \
+    if (code != musaSuccess) {                             \
       throw std::runtime_error(                            \
-          std::string("CUDA error: ") + std::string(msg)); \
+          std::string("MUSA error: ") + std::string(msg)); \
     }                                                      \
   } while (0)
 
 namespace torch::aot_inductor {
 
-using DeviceStreamType = cudaStream_t;
+using DeviceStreamType = musaStream_t;
 
 } // namespace torch::aot_inductor
-
-#else // !USE_CUDA
-
-#define AOTI_RUNTIME_DEVICE_CHECK(EXPR)            \
-  bool ok = EXPR;                                  \
-  if (!ok) {                                       \
-    throw std::runtime_error("CPU runtime error"); \
-  }
-
-namespace torch {
-namespace aot_inductor {
-
-using DeviceStreamType = void*;
-
-} // namespace aot_inductor
-} // namespace torch
-
-#endif // USE_CUDA
