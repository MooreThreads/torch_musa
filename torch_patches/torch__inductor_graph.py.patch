diff --git a/torch/_inductor/graph.py b/torch/_inductor/graph.py
index 2e2e2d1..e91dfbc 100644
--- a/torch/_inductor/graph.py
+++ b/torch/_inductor/graph.py
@@ -166,6 +166,19 @@ class GraphLowering(torch.fx.Interpreter):
             # CUDACombinedScheduling combines Triton and CUDA C++ scheduling for CUDA devices via delegation
             register_backend_for_device("cuda", CUDACombinedScheduling, WrapperCodeGen)
 
+        private_backend = torch._C._get_privateuse1_backend_name()
+        if (
+            private_backend != "privateuseone"
+            and get_scheduling_for_device(private_backend) is None
+        ):
+            from torch.utils.backend_registration import _get_custom_mod_func
+
+            try:
+                register_func = _get_custom_mod_func("_init_inductor_backend_registration")
+                register_func()
+            except RuntimeError:
+                pass
+
     def __init__(
         self,
         gm: torch.fx.GraphModule,
