diff --git a/torch/_dynamo/variables/ctx_manager.py b/torch/_dynamo/variables/ctx_manager.py
index 4ebcb06..4a8497d 100644
--- a/torch/_dynamo/variables/ctx_manager.py
+++ b/torch/_dynamo/variables/ctx_manager.py
@@ -798,11 +798,17 @@ class DisabledSavedTensorsHooksVariable(ContextWrappingVariable):
 class AutocastModeVariable(ContextWrappingVariable):
     @staticmethod
     def create(func, args, kwargs):
+        custom_backend = torch._C._get_privateuse1_backend_name()
+        custom_backend_mod = getattr(torch, custom_backend, None)
+        if custom_backend_mod:
+            custom_autocast_lst = [custom_backend_mod.amp.autocast]
+        else:
+            custom_autocast_lst = []
         assert func in [
             torch.amp.autocast_mode.autocast,
             torch.cuda.amp.autocast,
             torch.cpu.amp.autocast,
-        ]
+        ] + custom_autocast_lst
         # device_type : str,
         # dtype : Optional[_dtype] = None,
         # enabled : bool = True,
@@ -816,8 +822,11 @@ class AutocastModeVariable(ContextWrappingVariable):
             if key == "device_type" and func in [
                 torch.cuda.amp.autocast,
                 torch.cpu.amp.autocast,
-            ]:
-                arg = "cuda" if func is torch.cuda.amp.autocast else "cpu"
+            ] + custom_autocast_lst:
+                if func in custom_autocast_lst:
+                    arg = custom_backend
+                else:
+                    arg = "cuda" if func is torch.cuda.amp.autocast else "cpu"
             else:
                 arg = bound_args.arguments[key]
             if isinstance(arg, VariableTracker):
