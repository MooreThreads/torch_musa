diff --git a/torch/_dynamo/variables/ctx_manager.py b/torch/_dynamo/variables/ctx_manager.py
index 301b7f3..2f67823 100644
--- a/torch/_dynamo/variables/ctx_manager.py
+++ b/torch/_dynamo/variables/ctx_manager.py
@@ -737,11 +737,15 @@ class DisabledSavedTensorsHooksVariable(ContextWrappingVariable):
 class AutocastModeVariable(ContextWrappingVariable):
     @staticmethod
     def create(func, args, kwargs):
+        if custom_backend_mod := getattr(torch, torch._C._get_privateuse1_backend_name(), None):
+            custom_autocast_lst = [custom_backend_mod.amp.autocast]
+        else:
+            custom_autocast_lst = []
         assert func in [
             torch.amp.autocast_mode.autocast,
             torch.cuda.amp.autocast,
             torch.cpu.amp.autocast,
-        ]
+        ] + custom_autocast_lst
         # device_type : str,
         # dtype : Optional[_dtype] = None,
         # enabled : bool = True,
@@ -755,8 +759,13 @@ class AutocastModeVariable(ContextWrappingVariable):
             if key == "device_type" and func in [
                 torch.cuda.amp.autocast,
                 torch.cpu.amp.autocast,
-            ]:
-                arg = "cuda" if func is torch.cuda.amp.autocast else "cpu"
+            ] + custom_autocast_lst:
+                if func is torch.cuda.amp.autocast:
+                    arg = "cuda"
+                elif func in custom_autocast_lst:
+                    arg = torch._C._get_privateuse1_backend_name()
+                else:
+                    arg = "cpu"
             else:
                 arg = bound_args.arguments[key]
             if isinstance(arg, VariableTracker):
