diff --git a/torch/csrc/inductor/aoti_runtime/model.h b/torch/csrc/inductor/aoti_runtime/model.h
index 91df284..b661f1e 100644
--- a/torch/csrc/inductor/aoti_runtime/model.h
+++ b/torch/csrc/inductor/aoti_runtime/model.h
@@ -40,39 +40,35 @@ extern uint8_t _binary_constants_bin_end[];
 
 namespace {
 
-#ifdef USE_CUDA
+using MUSAPtr = std::unique_ptr<void, std::function<void(void*)>>;
 
-using CUDAPtr = std::unique_ptr<void, std::function<void(void*)>>;
-
-CUDAPtr RAII_cudaMalloc(size_t num_bytes) {
+MUSAPtr RAII_musaMalloc(size_t num_bytes) {
   void* data_ptr;
-  AOTI_RUNTIME_DEVICE_CHECK(cudaMalloc((void**)&data_ptr, num_bytes));
-  auto deleter = [](void* ptr) { AOTI_RUNTIME_DEVICE_CHECK(cudaFree(ptr)); };
-  return CUDAPtr(data_ptr, deleter);
+  AOTI_RUNTIME_DEVICE_CHECK(musaMalloc((void**)&data_ptr, num_bytes));
+  auto deleter = [](void* ptr) { AOTI_RUNTIME_DEVICE_CHECK(musaFree(ptr)); };
+  return MUSAPtr(data_ptr, deleter);
 }
 
-#endif // USE_CUDA
-
 } // anonymous namespace
 
 namespace torch::aot_inductor {
 using ConstantMap = std::unordered_map<std::string, RAIIAtenTensorHandle>;
 
-// valid device strs are: cpu, cuda, cuda:0, cuda:1, ...
+// valid device strs are: cpu, musa, musa:0, musa:1, ...
 // Update the list here if more devices are supported in the future
 inline void parse_device_str(
     const std::string& device_str,
     int32_t& device_type,
     int32_t& device_idx) {
-  std::regex re("(cpu|cuda)(:([0-9]+))?");
+  std::regex re("(cpu|musa)(:([0-9]+))?");
   std::smatch sm;
   bool matched = std::regex_match(device_str, sm, re);
   AOTI_RUNTIME_CHECK(matched, "Invalid device: " + device_str);
 
   if (sm[1].str() == "cpu") {
     device_type = aoti_torch_device_type_cpu();
-  } else if (sm[1].str() == "cuda") {
-    device_type = aoti_torch_device_type_cuda();
+  } else if (sm[1].str() == "musa") {
+    device_type = aoti_torch_device_type_musa();
   } else {
     AOTI_RUNTIME_CHECK(false, "Invalid device: " + device_str);
   }
@@ -97,30 +93,26 @@ class AOTInductorModelBase {
       size_t num_outputs,
       size_t num_constants,
       const std::string& device_str,
-      std::optional<std::string> cubin_dir)
+      std::optional<std::string> mubin_dir)
       : inputs_info_(num_inputs),
         outputs_info_(num_outputs),
         constants_info_(num_constants),
-        cubin_dir_(std::move(cubin_dir)) {
+        mubin_dir_(std::move(mubin_dir)) {
     parse_device_str(device_str, device_type_, device_idx_);
 
-#ifdef USE_CUDA
     if (device_idx_ == -1) {
-      AOTI_RUNTIME_DEVICE_CHECK(cudaGetDevice(&device_idx_));
+      AOTI_RUNTIME_DEVICE_CHECK(musaGetDevice(&device_idx_));
     }
-#endif // USE_CUDA
   }
 
   ~AOTInductorModelBase() {
-#ifdef USE_CUDA
     if (run_finished_) {
-      auto code = cudaEventDestroy(*run_finished_);
-      if (code != cudaSuccess) {
-        std::cerr << "Failed to destroy CUDA event in AOTInductor model: "
-                  << cudaGetErrorString(code) << std::endl;
+      auto code = musaEventDestroy(*run_finished_);
+      if (code != musaSuccess) {
+        std::cerr << "Failed to destroy MUSA event in AOTInductor model: "
+                  << musaGetErrorString(code) << std::endl;
       }
     }
-#endif // USE_CUDA
   }
 
   AOTInductorModelBase(AOTInductorModelBase&&) = delete;
@@ -138,47 +130,32 @@ class AOTInductorModelBase {
                           // borrowed
       DeviceStreamType stream,
       AOTIProxyExecutorHandle proxy_executor) {
-#ifdef USE_CUDA
     if (!run_finished_) {
-      cudaEvent_t run_finished;
-      AOTI_RUNTIME_DEVICE_CHECK(cudaEventCreate(&run_finished));
+      musaEvent_t run_finished;
+      AOTI_RUNTIME_DEVICE_CHECK(musaEventCreate(&run_finished));
       run_finished_.emplace(run_finished);
     }
 
     auto* model = static_cast<Model*>(this);
     model->run_impl(input_handles, output_handles, stream, proxy_executor);
-    AOTI_RUNTIME_DEVICE_CHECK(cudaEventRecord(*run_finished_, stream));
-#else // !USE_CUDA
-    run_finished_ = false;
-    auto* model = static_cast<Model*>(this);
-    model->run_impl(input_handles, output_handles, stream, proxy_executor);
-    run_finished_ = true;
-#endif // USE_CUDA
+    AOTI_RUNTIME_DEVICE_CHECK(musaEventRecord(*run_finished_, stream));
   }
 
   std::unordered_map<std::string, AtenTensorHandle> run_const_fold(
       DeviceStreamType stream,
       AOTIProxyExecutorHandle proxy_executor,
       bool initialization = false) {
-#ifdef USE_CUDA
     if (!run_finished_) {
-      cudaEvent_t run_finished;
-      AOTI_RUNTIME_DEVICE_CHECK(cudaEventCreate(&run_finished));
+      musaEvent_t run_finished;
+      AOTI_RUNTIME_DEVICE_CHECK(musaEventCreate(&run_finished));
       run_finished_.emplace(run_finished);
     }
-#else // USE_CUDA
-    run_finished_ = false;
-#endif // USE_CUDA
 
     auto* model = static_cast<Model*>(this);
     auto folded_constants =
         model->const_run_impl(stream, proxy_executor, initialization);
 
-#ifdef USE_CUDA
-    AOTI_RUNTIME_DEVICE_CHECK(cudaEventRecord(*run_finished_, stream));
-#else // USE_CUDA
-    run_finished_ = true;
-#endif // USE_CUDA
+    AOTI_RUNTIME_DEVICE_CHECK(musaEventRecord(*run_finished_, stream));
 
     return folded_constants;
   }
@@ -190,21 +167,20 @@ class AOTInductorModelBase {
     std::vector<size_t> constants_internal_offset(num_constants);
     if (device_type_ != aoti_torch_device_type_cpu()) {
       size_t blob_size = 0;
-      compute_cuda_constant_blob(blob_size, constants_internal_offset);
-#ifdef USE_CUDA
-      constant_blob_ = RAII_cudaMalloc(blob_size);
-#endif
+      compute_musa_constant_blob(blob_size, constants_internal_offset);
+
+      constant_blob_ = RAII_musaMalloc(blob_size);
     }
 
     size_t bytes_read = 0;
     for (size_t i = 0; i < num_constants; i++) {
       bool from_folded = this->constant_from_folded(i);
-#ifndef USE_CUDA
+
       if (from_folded) {
         // We do not reallocate and copy for CPU.
         continue;
       }
-#endif // USE_CUDA
+
       std::string name = this->constant_name(i);
       size_t data_size = this->constant_data_size(i);
       uint8_t* internal_ptr = (data_size != 0)
@@ -265,11 +241,9 @@ class AOTInductorModelBase {
     }
   }
 
-#ifdef USE_CUDA
-  CUDAPtr&& release_constant_blob() {
+  MUSAPtr&& release_constant_blob() {
     return std::move(constant_blob_);
   }
-#endif
 
   std::shared_ptr<std::vector<ConstantHandle>> get_constants_array() {
     return constants_;
@@ -284,31 +258,23 @@ class AOTInductorModelBase {
       size_t bytes_read,
       size_t data_size,
       bool skip_copy) {
-#ifdef USE_CUDA
     auto* constants_ptr = static_cast<uint8_t*>(constant_blob_.get());
     uint8_t* internal_ptr = constants_ptr + constant_offset;
     // Copy data to GPU memory
     // TODO: Handle shared storage case.
     if (!skip_copy) {
-      AOTI_RUNTIME_DEVICE_CHECK(cudaMemcpy(
+      AOTI_RUNTIME_DEVICE_CHECK(musaMemcpy(
           internal_ptr,
           _get_constants_start() + bytes_read,
           data_size,
-          cudaMemcpyHostToDevice));
+          musaMemcpyHostToDevice));
     }
     return internal_ptr;
-
-#else
-    // get pointer to constant which is packed in model during compile time.
-    AOTI_RUNTIME_CHECK(!skip_copy, "pure cpu mode doesn't support skip copy");
-    return _get_constants_start() + bytes_read;
-#endif // USE_CUDA
   }
 
-  void compute_cuda_constant_blob(
+  void compute_musa_constant_blob(
       size_t& blob_size,
       std::vector<size_t>& constants_internal_offset) {
-#ifdef USE_CUDA
     size_t num_constants = this->num_constants();
     // Compute required blob size with 64-alignment if on GPU.
     blob_size = 0;
@@ -321,7 +287,6 @@ class AOTInductorModelBase {
       constants_internal_offset[i] = blob_size;
       blob_size += data_size;
     }
-#endif // USE_CUDA
   }
 
   size_t num_inputs() const {
@@ -439,35 +404,29 @@ class AOTInductorModelBase {
 
   /// Returns true if the model is complete.
   bool is_finished() {
-#ifdef USE_CUDA
     if (!run_finished_) {
-      throw std::runtime_error{"Model CUDA event was not initialized"};
+      throw std::runtime_error{"Model MUSA event was not initialized"};
     }
 
-    auto event_status = cudaEventQuery(*run_finished_);
-    if (event_status == cudaSuccess) {
+    auto event_status = musaEventQuery(*run_finished_);
+    if (event_status == musaSuccess) {
       return true;
-    } else if (event_status == cudaErrorNotReady) {
+    } else if (event_status == musaErrorNotReady) {
       return false;
     }
 
     throw std::runtime_error(
         std::string("The model did not finish successfully. Error: ") +
-        cudaGetErrorString(cudaGetLastError()));
-#else // !USE_CUDA
-    return run_finished_;
-#endif // USE_CUDA
+        musaGetErrorString(musaGetLastError()));
   }
 
   /// Synchronizes completion event.
   void wait_for_completion() {
-#ifdef USE_CUDA
     if (!run_finished_) {
       throw std::runtime_error{"Model event was not initialized"};
     }
 
-    AOTI_RUNTIME_DEVICE_CHECK(cudaEventSynchronize(*run_finished_));
-#endif // USE_CUDA
+    AOTI_RUNTIME_DEVICE_CHECK(musaEventSynchronize(*run_finished_));
   }
 
  protected:
@@ -537,26 +496,22 @@ class AOTInductorModelBase {
   std::shared_ptr<ConstantMap> constants_map_;
   std::shared_ptr<std::vector<ConstantHandle>> constants_;
 
-#ifdef USE_CUDA
-  // Holds the blob storage for constants' at::Tensor for CUDA.
-  CUDAPtr constant_blob_;
-#endif // USE_CUDA
+  // Holds the blob storage for constants' at::Tensor for MUSA.
+  MUSAPtr constant_blob_;
+
 #ifdef USE_MMAP_SELF
   uint8_t* self_mmap = NULL;
 #endif
 
-  // A directory with CUDA binary files, e.g. compiled kernels, etc.
-  const std::optional<std::string> cubin_dir_;
+  // A directory with MUSA binary files, e.g. compiled kernels, etc.
+  const std::optional<std::string> mubin_dir_;
 
   // Record if the model finishes an inference run so that its owning
   // AOTModelContainer can re-use this instance.
-#ifdef USE_CUDA
-  std::optional<cudaEvent_t> run_finished_;
-#else // !USE_CUDA
-  bool run_finished_{};
-#endif
 
-  // Generated model uses this device index to create CUDA guards.
+  std::optional<musaEvent_t> run_finished_;
+
+  // Generated model uses this device index to create MUSA guards.
   int32_t device_type_{};
   int32_t device_idx_{};
 };
@@ -573,7 +528,7 @@ class AOTInductorModel : public AOTInductorModelBase<AOTInductorModel> {
       std::shared_ptr<ConstantMap> constants_map,
       std::shared_ptr<std::vector<ConstantHandle>> constants_array,
       const std::string& device_str,
-      std::optional<std::string> cubin_dir);
+      std::optional<std::string> mubin_dir);
 
   std::unordered_map<std::string, AtenTensorHandle> const_run_impl(
       DeviceStreamType stream,
@@ -606,12 +561,12 @@ class AOTInductorModel : public AOTInductorModelBase<AOTInductorModel> {
       std::shared_ptr<ConstantMap> constants_map,
       std::shared_ptr<std::vector<ConstantHandle>> constants_array,
       const std::string& device_str,
-      std::optional<std::string> cubin_dir) {
+      std::optional<std::string> mubin_dir) {
     return std::make_unique<AOTInductorModel>(
         std::move(constants_map),
         std::move(constants_array),
         device_str,
-        std::move(cubin_dir));
+        std::move(mubin_dir));
   }
 
  private:
