diff --git a/torch/csrc/inductor/aoti_runtime/model.h b/torch/csrc/inductor/aoti_runtime/model.h
index 0015b47..51dc145 100644
--- a/torch/csrc/inductor/aoti_runtime/model.h
+++ b/torch/csrc/inductor/aoti_runtime/model.h
@@ -42,7 +42,7 @@ extern uint8_t _binary_constants_bin_start[];
 // NOLINTNEXTLINE(*array*)
 extern uint8_t _binary_constants_bin_end[];
 
-#if defined(USE_CUDA) || defined(USE_XPU)
+#if 1 || defined(USE_XPU)
 // Compute required blob size with 64-alignment if on GPU.
 #define AOTI_CONST_ALIGNMENT 64
 #else
@@ -54,12 +54,12 @@ namespace {
 
 using RAIIDataPtr = std::unique_ptr<void, std::function<void(void*)>>;
 
-#ifdef USE_CUDA
+#if 1
 
 RAIIDataPtr RAII_gpuMalloc(size_t num_bytes) {
   void* data_ptr;
-  AOTI_RUNTIME_DEVICE_CHECK(cudaMalloc((void**)&data_ptr, num_bytes));
-  auto deleter = [](void* ptr) { AOTI_RUNTIME_DEVICE_CHECK(cudaFree(ptr)); };
+  AOTI_RUNTIME_DEVICE_CHECK(musaMalloc((void**)&data_ptr, num_bytes));
+  auto deleter = [](void* ptr) { AOTI_RUNTIME_DEVICE_CHECK(musaFree(ptr)); };
   return RAIIDataPtr(data_ptr, deleter);
 }
 
@@ -105,15 +105,15 @@ inline void parse_device_str(
     const std::string& device_str,
     int32_t& device_type,
     int32_t& device_idx) {
-  std::regex re("(cpu|cuda|xpu)(:([0-9]+))?");
+  std::regex re("(cpu|musa|xpu)(:([0-9]+))?");
   std::smatch sm;
   bool matched = std::regex_match(device_str, sm, re);
   AOTI_RUNTIME_CHECK(matched, "Invalid device: " + device_str);
 
   if (sm[1].str() == "cpu") {
     device_type = aoti_torch_device_type_cpu();
-  } else if (sm[1].str() == "cuda") {
-    device_type = aoti_torch_device_type_cuda();
+  } else if (sm[1].str() == "musa") {
+    device_type = aoti_torch_device_type_musa();
 #ifdef USE_XPU
   } else if (sm[1].str() == "xpu") {
     device_type = aoti_torch_device_type_xpu();
@@ -151,12 +151,12 @@ class AOTInductorModelBase {
         include_weights(include_weights) {
     parse_device_str(device_str, device_type_, device_idx_);
 
-#ifdef USE_CUDA
+#if 1
     if (device_idx_ == -1) {
-      AOTI_RUNTIME_DEVICE_CHECK(cudaGetDevice(&device_idx_));
+      AOTI_RUNTIME_DEVICE_CHECK(musaGetDevice(&device_idx_));
     } else {
       // If device_idx_ is passed in, we need to set the current device to it
-      AOTI_RUNTIME_DEVICE_CHECK(cudaSetDevice(device_idx_));
+      AOTI_RUNTIME_DEVICE_CHECK(musaSetDevice(device_idx_));
     }
 #endif // USE_CUDA
 #ifdef USE_XPU
@@ -170,12 +170,12 @@ class AOTInductorModelBase {
 
   // NOLINTNEXTLINE(modernize-use-equals-default)
   ~AOTInductorModelBase() {
-#ifdef USE_CUDA
+#if 1
     if (run_finished_) {
-      auto code = cudaEventDestroy(*run_finished_);
-      if (code != cudaSuccess) {
-        std::cerr << "Failed to destroy CUDA event in AOTInductor model: "
-                  << cudaGetErrorString(code) << std::endl;
+      auto code = musaEventDestroy(*run_finished_);
+      if (code != musaSuccess) {
+        std::cerr << "Failed to destroy MUSA event in AOTInductor model: "
+                  << musaGetErrorString(code) << std::endl;
       }
     }
 #endif // USE_CUDA
@@ -202,10 +202,10 @@ class AOTInductorModelBase {
                           // borrowed
       DeviceStreamType stream,
       AOTIProxyExecutorHandle proxy_executor) {
-#ifdef USE_CUDA
+#if 1
     if (!run_finished_) {
-      cudaEvent_t run_finished;
-      AOTI_RUNTIME_DEVICE_CHECK(cudaEventCreate(&run_finished));
+      musaEvent_t run_finished;
+      AOTI_RUNTIME_DEVICE_CHECK(musaEventCreate(&run_finished));
       run_finished_.emplace(run_finished);
     }
 #elif defined(USE_XPU)
@@ -221,8 +221,8 @@ class AOTInductorModelBase {
     auto* model = static_cast<Model*>(this);
     model->run_impl(input_handles, output_handles, stream, proxy_executor);
 
-#ifdef USE_CUDA
-    AOTI_RUNTIME_DEVICE_CHECK(cudaEventRecord(*run_finished_, stream));
+#if 1
+    AOTI_RUNTIME_DEVICE_CHECK(musaEventRecord(*run_finished_, stream));
 #elif defined(USE_XPU)
     run_finished_ = std::make_optional<sycl::event*>(new sycl::event(
         static_cast<sycl::queue*>(stream)->ext_oneapi_submit_barrier()));
@@ -253,10 +253,10 @@ class AOTInductorModelBase {
       DeviceStreamType stream,
       AOTIProxyExecutorHandle proxy_executor,
       bool initialization = false) {
-#ifdef USE_CUDA
+#if 1
     if (!run_finished_) {
-      cudaEvent_t run_finished;
-      AOTI_RUNTIME_DEVICE_CHECK(cudaEventCreate(&run_finished));
+      musaEvent_t run_finished;
+      AOTI_RUNTIME_DEVICE_CHECK(musaEventCreate(&run_finished));
       run_finished_.emplace(run_finished);
     }
 #elif defined(USE_XPU)
@@ -273,8 +273,8 @@ class AOTInductorModelBase {
     auto folded_constants =
         model->const_run_impl(stream, proxy_executor, initialization);
 
-#ifdef USE_CUDA
-    AOTI_RUNTIME_DEVICE_CHECK(cudaEventRecord(*run_finished_, stream));
+#if 1
+    AOTI_RUNTIME_DEVICE_CHECK(musaEventRecord(*run_finished_, stream));
 #elif defined(USE_XPU)
     // sycl::queue* queue_ptr = nullptr;
     // aoti_torch_get_current_sycl_queue((void**)&queue_ptr);
@@ -295,7 +295,7 @@ class AOTInductorModelBase {
     std::vector<size_t> constants_internal_offset(num_constants);
     size_t blob_size = 0;
     compute_constant_blob(blob_size, constants_internal_offset);
-#if defined(USE_CUDA) || defined(USE_XPU)
+#if 1 || defined(USE_XPU)
     constant_blob_ = RAII_gpuMalloc(blob_size);
 #else
     constant_blob_ = RAII_cpuMalloc(blob_size);
@@ -383,12 +383,12 @@ class AOTInductorModelBase {
       queue_ptr
           ->memcpy(internal_ptr, _get_constants_start() + bytes_read, data_size)
           .wait();
-#elif USE_CUDA
-      AOTI_RUNTIME_DEVICE_CHECK(cudaMemcpy(
+#elif 1
+      AOTI_RUNTIME_DEVICE_CHECK(musaMemcpy(
           internal_ptr,
           _get_constants_start() + bytes_read,
           data_size,
-          cudaMemcpyHostToDevice));
+          musaMemcpyHostToDevice));
 #else
       memcpy(internal_ptr, _get_constants_start() + bytes_read, data_size);
 #endif
@@ -531,21 +531,21 @@ class AOTInductorModelBase {
 
   /// Returns true if the model is complete.
   bool is_finished() {
-#ifdef USE_CUDA
+#if 1
     if (!run_finished_) {
-      throw std::runtime_error{"Model CUDA event was not initialized"};
+      throw std::runtime_error{"Model MUSA event was not initialized"};
     }
 
-    auto event_status = cudaEventQuery(*run_finished_);
-    if (event_status == cudaSuccess) {
+    auto event_status = musaEventQuery(*run_finished_);
+    if (event_status == musaSuccess) {
       return true;
-    } else if (event_status == cudaErrorNotReady) {
+    } else if (event_status == musaErrorNotReady) {
       return false;
     }
 
     throw std::runtime_error(
         std::string("The model did not finish successfully. Error: ") +
-        cudaGetErrorString(cudaGetLastError()));
+        musaGetErrorString(musaGetLastError()));
 #elif defined(USE_XPU)
     if (!run_finished_) {
       throw std::runtime_error{"Model XPU event was not initialized"};
@@ -561,12 +561,12 @@ class AOTInductorModelBase {
 
   /// Synchronizes completion event.
   void wait_for_completion() {
-#ifdef USE_CUDA
+#if 1
     if (!run_finished_) {
       throw std::runtime_error{"Model event was not initialized"};
     }
 
-    AOTI_RUNTIME_DEVICE_CHECK(cudaEventSynchronize(*run_finished_));
+    AOTI_RUNTIME_DEVICE_CHECK(musaEventSynchronize(*run_finished_));
 #endif // USE_CUDA
 #ifdef USE_XPU
     if (!run_finished_) {
@@ -662,8 +662,8 @@ class AOTInductorModelBase {
 
   // Record if the model finishes an inference run so that its owning
   // AOTModelContainer can re-use this instance.
-#ifdef USE_CUDA
-  std::optional<cudaEvent_t> run_finished_;
+#if 1
+  std::optional<musaEvent_t> run_finished_;
 #elif defined(USE_XPU)
   std::optional<sycl::event*> run_finished_;
 #else // !USE_CUDA
