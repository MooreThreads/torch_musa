diff --git a/torch/distributed/tensor/_random.py b/torch/distributed/tensor/_random.py
index db4b283..1d139b5 100644
--- a/torch/distributed/tensor/_random.py
+++ b/torch/distributed/tensor/_random.py
@@ -73,14 +73,14 @@ def manual_seed(seed: int, device_mesh: DeviceMesh) -> None:
         )
 
     # allgather the seed over the default PG
-    object_list = [seed] * dist.get_world_size()
-    dist.all_gather_object(object_list, seed)
-    for rank, object in enumerate(object_list):
-        if seed != int(object):
-            raise RuntimeError(
-                f"calling manual_seed function over {device_mesh} but received different seed values on ranks:",
-                f"seed on rank {dist.get_rank()} is {seed}, and seed on rank {rank} is {object}!",
-            )
+    #object_list = [seed] * dist.get_world_size()
+    #dist.all_gather_object(object_list, seed)
+    #for rank, object in enumerate(object_list):
+    #    if seed != int(object):
+    #        raise RuntimeError(
+    #            f"calling manual_seed function over {device_mesh} but received different seed values on ranks:",
+    #            f"seed on rank {dist.get_rank()} is {seed}, and seed on rank {rank} is {object}!",
+    #        )
     # instantiate a RNG tracker if haven't. By default DTensor uses an
     # OffsetBasedRNGTracker to perform random operators.
     global _rng_tracker
