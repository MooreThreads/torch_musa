diff --git a/torch/ao/quantization/fx/_lower_to_native_backend.py b/torch/ao/quantization/fx/_lower_to_native_backend.py
index 233d47e..bb6ee6d 100644
--- a/torch/ao/quantization/fx/_lower_to_native_backend.py
+++ b/torch/ao/quantization/fx/_lower_to_native_backend.py
@@ -307,6 +307,7 @@ STATIC_LOWER_FUSED_MODULE_MAP: dict[
     nni.ConvReLU1d: (nnqr.Conv1d, nniq.ConvReLU1d),
     nni.ConvReLU2d: (nnqr.Conv2d, nniq.ConvReLU2d),
     nni.ConvReLU3d: (nnqr.Conv3d, nniq.ConvReLU3d),
+    nni.ConvSiLU2d: (nnqr.Conv2d, nniq.ConvSiLU2d),
 }
 
 # The difference between STATIC_LOWER_FUSED_MODULE_TWO_INPUTS_MAP and STATIC_LOWER_FUSED_MODULE_MAP:
@@ -319,6 +320,7 @@ STATIC_LOWER_FUSED_MODULE_TWO_INPUTS_MAP: dict[
 ] = {
     nni.ConvAdd2d: (nnqr.Conv2d, nniq.ConvAdd2d),
     nni.ConvAddReLU2d: (nnqr.Conv2d, nniq.ConvAddReLU2d),
+    nni.ConvAddSiLU2d: (nnqr.Conv2d, nniq.ConvAddSiLU2d),
 }
 
 # Mapping from fused module class to a 2-tuple of:
@@ -1161,7 +1163,8 @@ def _lower_quantized_binary_op(model: GraphModule, qconfig_map: dict[str, QConfi
         model.graph.erase_node(q_node)
         if relu_node is not None:
             model.graph.erase_node(relu_node)
-        model.graph.erase_node(bop_node)
+        if not bop_node.users:
+            model.graph.erase_node(bop_node)
 
 
 def special_pattern_replacement(model: GraphModule):
