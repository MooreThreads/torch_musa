diff --git a/torch/ao/quantization/fx/_lower_to_native_backend.py b/torch/ao/quantization/fx/_lower_to_native_backend.py
index e0b7b76..f6dd384 100644
--- a/torch/ao/quantization/fx/_lower_to_native_backend.py
+++ b/torch/ao/quantization/fx/_lower_to_native_backend.py
@@ -307,6 +307,7 @@ STATIC_LOWER_FUSED_MODULE_MAP: Dict[
     nni.ConvReLU1d: (nnqr.Conv1d, nniq.ConvReLU1d),
     nni.ConvReLU2d: (nnqr.Conv2d, nniq.ConvReLU2d),
     nni.ConvReLU3d: (nnqr.Conv3d, nniq.ConvReLU3d),
+    nni.ConvSiLU2d: (nnqr.Conv2d, nniq.ConvSiLU2d),
 }
 
 # The difference between STATIC_LOWER_FUSED_MODULE_TWO_INPUTS_MAP and STATIC_LOWER_FUSED_MODULE_MAP:
@@ -319,6 +320,7 @@ STATIC_LOWER_FUSED_MODULE_TWO_INPUTS_MAP: Dict[
 ] = {
     nni.ConvAdd2d: (nnqr.Conv2d, nniq.ConvAdd2d),
     nni.ConvAddReLU2d: (nnqr.Conv2d, nniq.ConvAddReLU2d),
+    nni.ConvAddSiLU2d: (nnqr.Conv2d, nniq.ConvAddSiLU2d),
 }
 
 # Mapping from fused module class to a 2-tuple of:
@@ -1133,7 +1135,8 @@ def _lower_quantized_binary_op(model: GraphModule, qconfig_map: Dict[str, QConfi
         model.graph.erase_node(q_node)
         if relu_node is not None:
             model.graph.erase_node(relu_node)
-        model.graph.erase_node(bop_node)
+        if not bop_node.users:
+            model.graph.erase_node(bop_node)
 
 
 def special_pattern_replacement(model: GraphModule):
