diff --git a/torch/nn/parallel/_functions.py b/torch/nn/parallel/_functions.py
index 834d444..054cc61 100644
--- a/torch/nn/parallel/_functions.py
+++ b/torch/nn/parallel/_functions.py
@@ -93,6 +93,8 @@ class Scatter(Function):
         if torch.cuda.is_available() and ctx.input_device == -1:
             # Perform CPU to GPU copies in a background stream
             streams = [_get_stream(device) for device in target_gpus]
+        if torch.musa.is_available() and ctx.input_device == -1:
+            streams = [_get_stream(device) for device in target_gpus]
         outputs = comm.scatter(input, target_gpus, chunk_sizes, ctx.dim, streams)
         # Synchronize with the copy stream
         if streams is not None:
@@ -117,6 +119,12 @@ def _get_stream(device: int):
     global _streams
     if device == -1:
         return None
+    if hasattr(torch, 'musa') and torch.musa.is_available():
+        if _streams is None:
+            _streams = [None] * torch.musa.device_count()
+        if _streams[device] is None:
+            _streams[device] = torch.musa.Stream(device)
+        return _streams[device]
     if _streams is None:
         _streams = [None] * torch.cuda.device_count()
     if _streams[device] is None:
